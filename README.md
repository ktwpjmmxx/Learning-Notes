# GPT-2 学習履歴

![GPT-2](https://img.shields.io/badge/GPT--2-学習記録-blue)
![Python](https://img.shields.io/badge/Python-3.x-green)
![Google Colab](https://img.shields.io/badge/Google%20Colab-Ready-orange)

## 📖 概要

このリポジトリは、GPT-2に関する学習過程を記録したものです。日々の学習内容や実装内容を時系列で整理し、チャットボット開発に至るまでのプロセスを体系的に管理しています。

## 📁 プロジェクト構成

```
first_encounter_with_GPT-2/
└── Study_about_GPT-2/
    ├── models/           # 学習済みモデル保存先
    ├── datasets/         # 訓練データ
    ├── notebooks/        # Jupyter/Colab ノートブック
    └── docs/            # ドキュメント
```

---

## 📚 学習履歴

### 🔧 2025/08/13 - 基本環境構築
**Google Colab環境での基本セットアップ**

#### 環境設定
- ✅ **必要なライブラリのインストール**
  - 基本的なPythonライブラリの導入
- ✅ **計算環境の設定**
  - GPU/CPU判定による最適化
  - 乱数シードの固定（結果の再現性確保）

#### モデル・トークナイザー詳細設定
- ✅ **モデルサイズ選択**
  - 適切なGPT-2モデルサイズの決定
- ✅ **トークナイザー準備**
  - パディング設定を含む初期化
- ✅ **モデル読み込み**
  - 事前学習済みモデルのロード
- ✅ **デバイス転送 & パラメータ数確認**
  - GPU/CPUへの適切な転送
  - モデルパラメータ数の確認・表示

### 📊 2025/08/14 - データセット構築
**会話データセットの構築**

#### 会話データセットの設計
- ✅ **会話データセット作成関数の定義**
  - 会話のリストの各要素（辞書）は `{"user": "ユーザー発話", "bot": "ボット応答"}` の形式

#### Excelマクロの作成（業務効率化）
- ✅ **VBAマクロを使用したテンプレート自動化**
  - セル指定による文の移動機能
  - ⚠️ **課題**: 1セル内に複数の別セル文を入れ込む処理で難航中

### ⚡ 2025/08/15 - エラーハンドリング
**エラー発生時の対応処理の設定**

#### 例外処理の実装
- ✅ **正常処理と例外処理**
  - エラーハンドリングの基礎実装
  - 堅牢なコードベースの構築

### 🛠️ 2025/08/17 - データ前処理とコードレビュー
**会話データを学習可能な形にする前処理**

#### データ前処理
- ✅ **テキストのクリーニング**
- ✅ **特殊トークンによる構造化**
- ✅ **バッチトークン化**
- ✅ **Hugging Face Dataset形式への変換**

#### 全体復習
- ✅ **コードブロック1〜6の復習**
  - 全体の流れの理解
  - ブロック内のコードの動作確認

### ⚙️ 2025/08/19 - Tokenizer設定とTrainingArguments
**ChatBot制作時のtokenizerに必要な設定**

#### Tokenizer設定
- ✅ **基本設定の調整**
  - `max_length` と `truncation` の指定
  - EOSをPADの代用として使用
  - 会話開始・終了用の特殊トークン作成

#### コードブロック7の内容
- ✅ **TrainingArgumentsの定義**
  - エポック数、バッチサイズ、勾配更新頻度の設定
  - 学習率（3e-5）の指定
- ✅ **DataCollatorの設定**
  - 学習のまとめ方指定
  - ステップごとの保存、検証無効化
- ✅ **出力確認項目**
  - エポック数、バッチサイズ、勾配累積、学習率、FP16など

### 🏃‍♂️ 2025/08/20 - 学習実行とモデル保存
**コードブロック8：ファインチューニングの実装**

#### 学習関数の実装
- ✅ **`train_chatbot_model()` 関数の作成**
  - Trainerクラスを使った学習ループの自動化
  - 学習時間の計測機能

#### エラーハンドリングの強化
- ✅ **堅牢な例外処理**
  - try-except文による例外処理
  - メモリ不足時の対処方法提示
  - 学習中断時の適切なエラーメッセージ

#### モデル保存機能
- ✅ **学習済みモデルの保存**
  - モデルの重み保存
  - トークナイザー設定の保存
  - 学習履歴のJSON形式での記録
  - 学習結果の可視化用データ作成

### 🎯 2025/08/27 - AI博覧会2025 Summer
**生成AIの現状と未来に関する講演参加**

#### 講演1: 間もなく登場から3年、生成AI活用で変わる社会と仕事のかたち（西脇 資哲氏）
- 📌 **Microsoft Copilot活用法**
  - Officeアプリケーションでの実践的な使用方法
- 🌏 **国際的な視点**
  - 日本と諸外国の生成AIに対する意識の違い
- 🎯 **AI選択指針**
  - 目的によって異なる生成AIの種類と選択基準

#### 講演2: ロボットで生成AIをリアル世界に召喚する（成迫 剛志氏）
- 📈 **GPTの歴史的発展**
  - General Purpose Technologyとしての歴史的推移
- 🔄 **社会変革の考察**
  - Before AIとAfter AIによる社会的な違い
- 🤖 **実用事例**
  - アームロボット×AIを駆使した様々なサービス紹介

### 💬 2025/08/28 - チャットボット実装の詳細
**GPT-2モデルを使用したGoogle Colabでの小規模チャットボット実装**

#### 実装に必要な要素
- 🔧 **GPT-2 Pre-Trained Model**
  - Hugging Faceからの取得
- 🔤 **Tokenizer**
  - テキスト処理の中核機能
- 💭 **会話管理部分**
  - コードで制作するConversation_Manager
- ⚡ **推論設定**
  - `torch.no_grad()` などの最適化設定

#### Tokenizerの内部構造
- 🔄 **基本機能**
  - エンコード / デコードの処理
  - BPE（Byte Pair Encoding）の仕組み
- 🏷️ **特殊要素**
  - 特殊トークン（`<|endoftext|>` など）
  - 語彙（vocab）の管理

### 🐍 2025/09/03 - Pythonの復習とAI戦略研究
**チャットボット実装に向けた技術的基盤の整備**

#### Pythonの復習
- 📝 **クラスの仕組みについて**
  - `__init__`（イニシャライザ）の仕組み
  - `self` について

#### AI戦略会議・AI制度研究会

##### 基本的な考え方
1. **イノベーション促進とリスク対応の両立**
   - 🔬 **研究開発支援**: データ整備、計算資源、人材育成
   - ⚖️ **法令とソフトローの適切な組み合わせ**: 事業者の自主性を尊重し、法規制は必要最小限に

2. **関係主体の整理**
   - 👨‍💻 **AI開発者**: データ収集、モデル学習を行う者
   - 🏢 **AI提供者**: AIをサービスとして提供する者
   - 👤 **AI利用者**: AIサービスを利用する者
   - 🌍 **国外事業者も対象**: 国内事業者との公平性確保

##### 制度化の方向性
**法制度による対応が必要な事項**
- 🏛️ **政府の司令塔機能**: 法定化による権限明確化
- 🔍 **透明性・適正性確保**: 事業者の情報提供・協力義務
- 📊 **実態調査・情報収集**: 政府の調査権限と事業者の協力義務
- ⚠️ **重大インシデント対応**: 政府の調査・指導助言権限

### 🔧 2025/09/04 - 会話管理システム設計
**ConversationManagerの実装**

#### 会話管理システム(ConversationManager)の設定
- ✅ **モデルの選択機能**
  - `model_options`にgpt2, gpt2-mediumそれぞれのリストを用意
  - 各モデルの整理項目：
    - `parameters`（パラメータ数）
    - `memory_usage`（推定メモリ使用量）
    - `inference_speed`（推論速度）
    - `quality`（会話の質）

- ✅ **conversation_history**
  - 会話全体の履歴を格納するリストの用意

- ✅ **コンテキスト構築**
  - 会話履歴から直近の5件のみを取り出して保存するコンテキストを用意→モデルに渡す

---

## 📈 学習統計

| 📊 項目 | 📋 詳細 |
|---------|---------|
| **🚀 開始日** | 2025/08/13 |
| **📅 学習日数** | 10日目（2025/09/04時点） |
| **✅ 完了セクション** | 9 |
| **🎯 主な成果** | 環境構築、データ設計、前処理、Tokenizer設定、学習実行、チャットボット実装、会話管理システム設計 |

## 🔗 参考資料

- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [GPT-2 Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [Google Colab](https://colab.research.google.com/)

---

*📝 最終更新: 2025/09/04*